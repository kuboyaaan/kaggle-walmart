{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_columns', 100)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "\n",
    "BASE_DIR = './walmart/input/walmart-recruiting-store-sales-forecasting/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(BASE_DIR + 'train.csv.zip')\n",
    "test = pd.read_csv(BASE_DIR + 'test.csv.zip')\n",
    "stores = pd.read_csv(BASE_DIR + 'stores.csv')\n",
    "features = pd.read_csv(BASE_DIR + 'features.csv.zip')\n",
    "submission = pd.read_csv(BASE_DIR + 'sampleSubmission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(stores, on='Store', how='left')\n",
    "train = train.merge(features, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
    "\n",
    "test = test.merge(stores, on='Store', how='left')\n",
    "test = test.merge(features, on=['Store', 'Date', 'IsHoliday'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_function(df):\n",
    "    df['Date'] = pd.to_datetime(df.Date)\n",
    "    df['year'] = df.Date.dt.year\n",
    "    df['month'] = df.Date.dt.month\n",
    "    df['day'] = df.Date.dt.day\n",
    "    return df\n",
    "    \n",
    "train = datetime_function(train)\n",
    "test = datetime_function(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Holiday_type(df):\n",
    "    df['HolidayType'] = 0\n",
    "    idx = (df.IsHoliday==True) & (df.month==2)\n",
    "    df.loc[idx, 'HolidayType'] = 1\n",
    "    idx = (df.IsHoliday==True) & (df.month==9)\n",
    "    df.loc[idx, 'HolidayType'] = 2\n",
    "    idx = (df.IsHoliday==True) & (df.month==11)\n",
    "    df.loc[idx, 'HolidayType'] = 3\n",
    "    idx = (df.IsHoliday==True) & (df.month==12)\n",
    "    df.loc[idx, 'HolidayType'] = 4\n",
    "    return df\n",
    "\n",
    "train = Holiday_type(train)\n",
    "test = Holiday_type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(train, test):\n",
    "    type_le = LabelEncoder()\n",
    "    train['Type'] = type_le.fit_transform(train['Type'])\n",
    "    test['Type'] = type_le.transform(test['Type'])\n",
    "    \n",
    "    holiday_le = LabelEncoder()\n",
    "    train['IsHoliday'] = holiday_le.fit_transform(train['IsHoliday'])\n",
    "    test['IsHoliday'] = holiday_le.transform(test['IsHoliday'])\n",
    "    return train, test\n",
    "\n",
    "train, test = label_encoder(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holiday_relation(df):\n",
    "    idx = df.IsHoliday == True\n",
    "    before = (df.loc[idx, 'Date'] - datetime.timedelta(days=7))\n",
    "    after = (df.loc[idx, 'Date'] + datetime.timedelta(days=7))\n",
    "\n",
    "    before_idx = df.Date.isin(before.tolist())\n",
    "    after_idx = df.Date.isin(after.tolist())\n",
    "    # train['HolidayRelation'] = np.nan\n",
    "    df.loc[idx, 'HolidayRelation'] = 0\n",
    "    df.loc[before_idx, 'HolidayRelation'] = -1\n",
    "    df.loc[after_idx, 'HolidayRelation'] = 1\n",
    "    return df\n",
    "\n",
    "train = holiday_relation(train)\n",
    "test = holiday_relation(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store + Deptを明示的に関連づける\n",
    "def store_dept_relation(train, test):\n",
    "    train['StoreDept'] = list(map(lambda x, y: str(x) + '_' + str(y), train['Store'], train['Dept']))\n",
    "    test['StoreDept'] = list(map(lambda x, y: str(x) + '_' + str(y), test['Store'], test['Dept']))\n",
    "\n",
    "    all_StoreDept = list(train['StoreDept'].unique())\n",
    "    StoreDept_map = dict(zip(all_StoreDept, np.arange(len(all_StoreDept))))\n",
    "\n",
    "    train['StoreDeptCategory'] = train['StoreDept'].map(StoreDept_map)\n",
    "    test['StoreDeptCategory'] = test['StoreDept'].map(StoreDept_map)\n",
    "    return train, test\n",
    "\n",
    "train, test = store_dept_relation(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 周期特徴\n",
    "def encode(df, col):\n",
    "    df[col + '_cos'] = np.cos(2 * np.pi * df[col]/df[col].max())\n",
    "    df[col + '_sin'] = np.sin(2 * np.pi * df[col]/df[col].max())\n",
    "    return df\n",
    "train = encode(train, 'month')\n",
    "test = encode(test, 'month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量選択1:feature importanceによる\n",
    "train = train.drop([\"Temperature\", 'CPI', 'Fuel_Price', 'Unemployment'], axis=1)\n",
    "test = test.drop([\"Temperature\", 'CPI', 'Fuel_Price', 'Unemployment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV戦略\n",
    "idx1 = train.Date>='2011-11-01'\n",
    "idx2 = train.Date<'2011-11-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量選択2\n",
    "train = train.drop(['Date', 'StoreDept', 'year', 'month', 'day'], axis=1)\n",
    "test = test.drop(['Date', 'StoreDept', 'year', 'month', 'day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Weekly_Sales']\n",
    "train = train.drop('Weekly_Sales', axis=1)\n",
    "\n",
    "categorical_features = ['Store', 'Dept', 'IsHoliday', 'Type', 'HolidayType', 'HolidayRelation', 'StoreDeptCategory']\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 1300,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"metric\": \"rmse\",\n",
    "}\n",
    "\n",
    "X1 = train.loc[idx2, :]\n",
    "X2 = train.loc[idx1, :]\n",
    "X = train\n",
    "\n",
    "y1 = y_train.loc[idx2]\n",
    "y2 = y_train.loc[idx1]\n",
    "y = y_train\n",
    "\n",
    "d1 = lgb.Dataset(X1, label=y1, categorical_feature=categorical_features, free_raw_data=False)\n",
    "d2 = lgb.Dataset(X2, label=y2, categorical_feature=categorical_features, free_raw_data=False)\n",
    "d = lgb.Dataset(X, label=y, categorical_feature=categorical_features, free_raw_data=False)\n",
    "\n",
    "watchlist1 = [d1, d2]\n",
    "watchlist2 = [d2, d1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building model with first\")\n",
    "model1 = lgb.train(params, train_set=d1, num_boost_round=1000, valid_sets=watchlist1, verbose_eval=200, early_stopping_rounds=200)\n",
    "print(\"Building model with second\")\n",
    "model2 = lgb.train(params, train_set=d2, num_boost_round=1000, valid_sets=watchlist2, verbose_eval=200, early_stopping_rounds=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 1300,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"metric\": \"rmse\",\n",
    "    'num_iterations': 700,\n",
    "}\n",
    "\n",
    "model3 = lgb.train(params, train_set=d, num_boost_round=1000, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X1, X2, X, y1, y2, y, d1, d2, d, watchlist1, watchlist2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの予測\n",
    "pred1 = model1.predict(test, num_iteration=model1.best_iteration)\n",
    "pred2 = model2.predict(test, num_iteration=model2.best_iteration)\n",
    "pred3 = model3.predict(test, num_iteration=model3.best_iteration)\n",
    "\n",
    "# cvの結果から重みを考える\n",
    "param = {'model1': 0, 'model2': 0.8, 'model3': 0.2}\n",
    "pred = pred1*param['model1'] + pred2*param['model2'] + pred3*param['model3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Weekly_Sales'] = pred\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
